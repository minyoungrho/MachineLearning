{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pick up from where we have left off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>lung_capacity</th>\n",
       "      <th>body_temperature</th>\n",
       "      <th>has_covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132.894691</td>\n",
       "      <td>6.931665</td>\n",
       "      <td>39.270112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.128239</td>\n",
       "      <td>6.715135</td>\n",
       "      <td>37.005833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.982006</td>\n",
       "      <td>6.580677</td>\n",
       "      <td>38.079465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112.337762</td>\n",
       "      <td>5.482720</td>\n",
       "      <td>37.662576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113.165263</td>\n",
       "      <td>6.664360</td>\n",
       "      <td>36.922810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>116.208860</td>\n",
       "      <td>7.408413</td>\n",
       "      <td>37.088040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>108.632769</td>\n",
       "      <td>6.854598</td>\n",
       "      <td>36.226869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>137.732933</td>\n",
       "      <td>3.548004</td>\n",
       "      <td>35.543415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>108.552490</td>\n",
       "      <td>2.931925</td>\n",
       "      <td>37.007822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>122.614886</td>\n",
       "      <td>7.499205</td>\n",
       "      <td>35.977492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     blood_pressure  lung_capacity  body_temperature  has_covid\n",
       "0        132.894691       6.931665         39.270112          0\n",
       "1        117.128239       6.715135         37.005833          1\n",
       "2        108.982006       6.580677         38.079465          0\n",
       "3        112.337762       5.482720         37.662576          0\n",
       "4        113.165263       6.664360         36.922810          1\n",
       "..              ...            ...               ...        ...\n",
       "995      116.208860       7.408413         37.088040          0\n",
       "996      108.632769       6.854598         36.226869          1\n",
       "997      137.732933       3.548004         35.543415          0\n",
       "998      108.552490       2.931925         37.007822          0\n",
       "999      122.614886       7.499205         35.977492          1\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../data/synth_covid.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['blood_pressure', 'lung_capacity', 'body_temperature', 'has_covid'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[['blood_pressure','lung_capacity','body_temperature']], \n",
    "                                                    dataset['has_covid'], test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the models, we will use **accuracy score**. \n",
    "\n",
    "To read more about different available metrics for quantifying the quality of predictions in scikit-learn library, read [this](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:\n",
    "\n",
    " - If you use linear regression in classification setting, the predicted y will be in continuous variables and not guaranteed to be between 0 and 1\n",
    " - Since we want to ensure that the predicted y is in between 0 and 1 to represent probability of \"has_covid\", we will use logistic regression\n",
    " - Further reading: [Difference between linear regression and logistic classifier](https://www.analyticsvidhya.com/blog/2020/12/beginners-take-how-logistic-regression-is-related-to-linear-regression/#:~:text=The%20Differences%20between%20Linear%20Regression,Logistic%20regression%20provides%20discreet%20output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43426848, 0.09288054, 0.14663457, 0.67036364, 0.48697863,\n",
       "       0.5940974 , 0.56330369, 0.56909352, 0.20873046, 0.17199413,\n",
       "       0.22273411, 0.45593934, 0.40951834, 0.14715723, 0.55148565,\n",
       "       0.14108294, 0.31749801, 0.53552206, 0.52404836, 0.12301633,\n",
       "       0.70907362, 0.0832256 , 0.28436488, 0.37810261, 0.25449338,\n",
       "       0.06306554, 0.14359515, 0.41702497, 0.70521321, 0.14118301,\n",
       "       0.50936841, 0.67575592, 0.4099779 , 0.55332484, 0.43124032,\n",
       "       0.16477004, 0.47377962, 0.4362375 , 0.1683291 , 0.56986948,\n",
       "       0.24311343, 0.62342061, 0.42377949, 0.22210576, 0.30355413,\n",
       "       0.13107423, 0.2190103 , 0.54743355, 0.10706753, 0.26720176,\n",
       "       0.12733672, 0.79219387, 0.19000976, 0.37393021, 0.11496717,\n",
       "       0.72858266, 0.3214984 , 0.60071608, 0.33637054, 0.33322601,\n",
       "       0.14161125, 0.35333746, 0.26302906, 0.42901798, 0.3147192 ,\n",
       "       0.27139953, 0.32954598, 0.2674246 , 0.54791268, 0.31170574,\n",
       "       0.60578821, 0.48048262, 0.42466278, 0.34406679, 0.38837871,\n",
       "       0.34818642, 0.17449558, 0.16993479, 0.2168451 , 0.23631233,\n",
       "       0.25453894, 0.41178709, 0.27878413, 0.14232392, 0.73684342,\n",
       "       0.3370336 , 0.74828947, 0.42272579, 0.41021845, 0.17683815,\n",
       "       0.69842154, 0.52493894, 0.43291899, 0.34297545, 0.20536136,\n",
       "       0.08701861, 0.29649714, 0.49469395, 0.3226185 , 0.22653641,\n",
       "       0.75940122, 0.57048335, 0.24446992, 0.16453207, 0.79245888,\n",
       "       0.19804429, 0.08075604, 0.08297166, 0.21330113, 0.37315795,\n",
       "       0.21100225, 0.48182367, 0.33460918, 0.55118653, 0.22742111,\n",
       "       0.39623879, 0.28234036, 0.24153831, 0.80673193, 0.67717636,\n",
       "       0.34640143, 0.37015147, 0.73676159, 0.72712384, 0.32205744,\n",
       "       0.26156605, 0.16607907, 0.30868879, 0.5608257 , 0.31781693,\n",
       "       0.66560538, 0.35578192, 0.40744946, 0.31208303, 0.62532484,\n",
       "       0.25487555, 0.24120685, 0.51377515, 0.27233472, 0.1350718 ,\n",
       "       0.46970071, 0.27029707, 0.58506136, 0.22798262, 0.08554308,\n",
       "       0.64440068, 0.14736459, 0.72364078, 0.19309297, 0.1640236 ,\n",
       "       0.3179137 , 0.31897624, 0.09707523, 0.14578174, 0.42662733,\n",
       "       0.25832047, 0.13348132, 0.06749205, 0.15867401, 0.48908734,\n",
       "       0.24658736, 0.21065641, 0.26565806, 0.11344117, 0.29989872,\n",
       "       0.35758201, 0.1356678 , 0.09295357, 0.34483154, 0.12279253,\n",
       "       0.41740025, 0.38472376, 0.51776813, 0.30934432, 0.37522164,\n",
       "       0.64095973, 0.57910031, 0.23444454, 0.30254642, 0.09905673,\n",
       "       0.5235761 , 0.73897155, 0.15035468, 0.2922378 , 0.18670128,\n",
       "       0.22592515, 0.36090683, 0.07674731, 0.29933436, 0.48431969,\n",
       "       0.64351183, 0.15178193, 0.28888549, 0.09094873, 0.23810661,\n",
       "       0.13156137, 0.6036617 , 0.64936917, 0.71482362, 0.3953115 ,\n",
       "       0.45777896, 0.23320716, 0.29426918, 0.52923053, 0.14116953,\n",
       "       0.48612619, 0.35605136, 0.13504088, 0.26127422, 0.15625823,\n",
       "       0.25791797, 0.83633221, 0.14575589, 0.6214573 , 0.24146439,\n",
       "       0.70463067, 0.50561839, 0.27064777, 0.60607552, 0.63127171,\n",
       "       0.33460174, 0.31631567, 0.60048228, 0.25731587, 0.21941363,\n",
       "       0.28722604, 0.11678751, 0.35748947, 0.36021108, 0.38249726,\n",
       "       0.4117109 , 0.29401538, 0.74441513, 0.54710503, 0.26347406,\n",
       "       0.09612887, 0.19172888, 0.45354388, 0.31698743, 0.04338328,\n",
       "       0.8888495 , 0.39150528, 0.75571053, 0.33237601, 0.44102469,\n",
       "       0.26258413, 0.1806801 , 0.58701732, 0.18294669, 0.41111232,\n",
       "       0.5519855 , 0.33457395, 0.30610024, 0.2003661 , 0.6357609 ,\n",
       "       0.20894022, 0.42505196, 0.23712623, 0.25897972, 0.17427167,\n",
       "       0.28504476, 0.79711364, 0.14771243, 0.11666847, 0.25043546,\n",
       "       0.08077427, 0.27472   , 0.27862354, 0.28992679, 0.22353141,\n",
       "       0.599141  , 0.27500957, 0.13561565, 0.50035678, 0.13810322,\n",
       "       0.26384208, 0.69322396, 0.70559551, 0.28180185, 0.37492606,\n",
       "       0.27895588, 0.48332339, 0.57919012, 0.08044619, 0.20072711,\n",
       "       0.62423917, 0.65363612, 0.38246993, 0.6078636 , 0.63068419,\n",
       "       0.49936966, 0.50023742, 0.29150597, 0.48128691, 0.34123042,\n",
       "       0.18799821, 0.16948066, 0.20835338, 0.41611585, 0.44730905,\n",
       "       0.28049879, 0.69274301, 0.42008627, 0.37611683, 0.4342423 ,\n",
       "       0.44367224, 0.2315791 , 0.94756834, 0.62859424, 0.27899526,\n",
       "       0.75116168, 0.25380993, 0.69938374, 0.47310802, 0.75698762,\n",
       "       0.28089345, 0.13556649, 0.11330515, 0.30191764, 0.32767238,\n",
       "       0.15097848, 0.2732509 , 0.31064465, 0.19633233, 0.4046604 ,\n",
       "       0.38216828, 0.23717762, 0.44609425, 0.31777678, 0.20140305,\n",
       "       0.57733305, 0.56708453, 0.1676405 , 0.28342928, 0.24276314,\n",
       "       0.11284387, 0.05853046, 0.50158532, 0.59057878, 0.17701917,\n",
       "       0.55832608, 0.72127438, 0.20953959, 0.31801128, 0.65195653,\n",
       "       0.13553392, 0.22612213, 0.1285875 , 0.22614444, 0.8123168 ,\n",
       "       0.55924409, 0.19853533, 0.23206604, 0.09274853, 0.15130594,\n",
       "       0.29773329, 0.12264086, 0.36500172, 0.6442498 , 0.17013887,\n",
       "       0.39956187, 0.3488103 , 0.2691309 , 0.60013897, 0.248094  ,\n",
       "       0.3425852 , 0.23042995, 0.32675092, 0.36118015, 0.72528763,\n",
       "       0.23659601, 0.33862451, 0.1856475 , 0.45507789, 0.33649964,\n",
       "       0.55522997, 0.17960797, 0.26594147, 0.27969067, 0.48859732,\n",
       "       0.31219266, 0.66888625, 0.09911771, 0.32634623, 0.548703  ,\n",
       "       0.11935964, 0.2824684 , 0.3123455 , 0.48196601, 0.29079075,\n",
       "       0.21141692, 0.22089815, 0.41005203, 0.24390347, 0.26271899,\n",
       "       0.17625045, 0.19149323, 0.18405933, 0.49910887, 0.26375253])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic': 0.68}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "losses['Logistic'] = accuracy_score(y_test, lr.predict(X_test))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic': 0.6273864384463463}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "losses['Logistic'] = roc_auc_score(y_test, lr.predict(X_test))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    " - Effective in high dimensional spaces.\n",
    " - Still effective in cases where number of dimensions is greater than the number of samples.\n",
    " - Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    " - Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    " - If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    " - SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic  :  0.68\n",
      "SVM (linear)  :  0.6125\n"
     ]
    }
   ],
   "source": [
    "losses['SVM (linear)'] = accuracy_score(y_test, clf.predict(X_test).round())\n",
    "for key, value in losses.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic  :  0.68\n",
      "SVM (linear)  :  0.6125\n",
      "SVM (polynomial)  :  0.615\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly')\n",
    "clf.fit(X_train, y_train)\n",
    "losses['SVM (polynomial)'] = accuracy_score(y_test, clf.predict(X_test).round())\n",
    "for key, value in losses.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors\n",
    "\n",
    "We are going to go over k-nearest neightbor algorithm (knn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic  :  0.68\n",
      "SVM (linear)  :  0.6125\n",
      "SVM (polynomial)  :  0.615\n",
      "KNN  :  0.655\n"
     ]
    }
   ],
   "source": [
    "losses['KNN'] = accuracy_score(y_test, knn.predict(X_test).round())\n",
    "for key, value in losses.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic  :  0.68\n",
      "SVM (linear)  :  0.6125\n",
      "SVM (polynomial)  :  0.615\n",
      "KNN  :  0.655\n",
      "KNN (10)  :  0.6525\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train, y_train)\n",
    "losses['KNN (10)'] = accuracy_score(y_test, knn.predict(X_test).round())\n",
    "for key, value in losses.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "XGBoost is an algorithm that has recently been dominating applied machine learning and Kaggle competitions for structured or tabular data.\n",
    "\n",
    "XGBoost is an implementation of gradient boosted decision trees designed for speed and performance.\n",
    "\n",
    "[Further reading](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:55:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic  :  0.68\n",
      "SVM (linear)  :  0.6125\n",
      "SVM (polynomial)  :  0.615\n",
      "KNN  :  0.655\n",
      "KNN (10)  :  0.6525\n",
      "XGBoost  :  0.61\n"
     ]
    }
   ],
   "source": [
    "losses['XGBoost'] = accuracy_score(y_test, xgb.predict(X_test).round())\n",
    "for key, value in losses.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:55:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Logistic  :  0.68\n",
      "SVM (linear)  :  0.6125\n",
      "SVM (polynomial)  :  0.615\n",
      "KNN  :  0.655\n",
      "KNN (10)  :  0.6525\n",
      "XGBoost  :  0.61\n",
      "XGBoost: maxdepth3  :  0.64\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=3)\n",
    "xgb.fit(X_train, y_train)\n",
    "losses['XGBoost: maxdepth3'] = accuracy_score(y_test, xgb.predict(X_test).round())\n",
    "for key, value in losses.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- [User Guide for scikit-learn](https://scikit-learn.org/stable/user_guide.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
